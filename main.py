# main.py
import os
import sys
import json
import asyncio
import aiohttp
import tiktoken
from typing import List, Optional
import argparse
from pathlib import Path
import time
from datetime import datetime

class GeminiFileProcessor:
    def __init__(self, api_key: str, model: str = "gemini-2.0-flash", paid_tier: bool = False):
        self.api_key = api_key
        self.model = model
        self.paid_tier = paid_tier
        self.encoding = tiktoken.get_encoding("cl100k_base")
        
        # –õ–∏–º–∏—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π –∏ –º–æ–¥–µ–ª–µ–π
        if paid_tier:
            self.rate_limits = {
                "gemini-2.0-flash": {"rpm": 2000, "tpm": 4000000, "rpd": 10000000},
                "gemini-2.0-flash-lite": {"rpm": 4000, "tpm": 4000000, "rpd": 10000000},
                "gemini-2.5-flash": {"rpm": 1000, "tpm": 1000000, "rpd": 10000},
                "gemini-2.5-flash-lite": {"rpm": 4000, "tpm": 4000000, "rpd": 10000000},
                "gemini-2.5-pro": {"rpm": 150, "tpm": 2000000, "rpd": 10000},
                "gemini-1.5-flash": {"rpm": 2000, "tpm": 4000000, "rpd": None},
                "gemini-1.5-pro": {"rpm": 1000, "tpm": 4000000, "rpd": None}
            }
        else:
            # Free Tier –ª–∏–º–∏—Ç—ã
            self.rate_limits = {
                "gemini-2.0-flash": {"rpm": 15, "tpm": 1000000, "rpd": 200},
                "gemini-2.0-flash-lite": {"rpm": 30, "tpm": 1000000, "rpd": 200},
                "gemini-2.5-flash": {"rpm": 10, "tpm": 250000, "rpd": 250},
                "gemini-2.5-flash-lite": {"rpm": 15, "tpm": 250000, "rpd": 1000},
                "gemini-2.5-pro": {"rpm": 5, "tpm": 250000, "rpd": 100},
                "gemini-1.5-flash": {"rpm": 15, "tpm": 250000, "rpd": 50},
                "gemini-1.5-pro": {"rpm": 2, "tpm": 32000, "rpd": 50}
            }
        
        self.current_limits = self.rate_limits.get(model, {"rpm": 15, "tpm": 250000, "rpd": 200})
        
        tier_name = "–ü–ª–∞—Ç–Ω—ã–π" if paid_tier else "Free"
        print(f"ü§ñ –ú–æ–¥–µ–ª—å: {model}")
        print(f"üí≥ –£—Ä–æ–≤–µ–Ω—å: {tier_name}")
        print(f"üìä –õ–∏–º–∏—Ç—ã: {self.current_limits['rpm']} RPM, {self.current_limits['tpm']:,} TPM")
        
    def count_tokens(self, text: str) -> int:
        """–ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ"""
        return len(self.encoding.encode(text))
    
    def split_into_chunks(self, text: str, prompt: str, max_chunk_tokens: int) -> List[str]:
        """–†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏ —Å —É—á–µ—Ç–æ–º –ª–∏–º–∏—Ç–æ–≤"""
        prompt_tokens = self.count_tokens(prompt)
        available_tokens = max_chunk_tokens - prompt_tokens - 2000  # —Ä–µ–∑–µ—Ä–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
        
        if available_tokens <= 0:
            raise ValueError(f"–ü—Ä–æ–º–ø—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π ({prompt_tokens} —Ç–æ–∫–µ–Ω–æ–≤)")
        
        chunks = []
        current_chunk = ""
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∞–±–∑–∞—Ü–∞–º
        paragraphs = text.split('\n\n')
        
        for paragraph in paragraphs:
            paragraph_tokens = self.count_tokens(paragraph)
            current_chunk_tokens = self.count_tokens(current_chunk)
            
            if current_chunk_tokens + paragraph_tokens > available_tokens:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                    current_chunk = paragraph
                else:
                    # –ï—Å–ª–∏ –∞–±–∑–∞—Ü —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
                    sentences = paragraph.split('. ')
                    for sentence in sentences:
                        sentence_with_dot = sentence + ". " if not sentence.endswith('.') else sentence + " "
                        if self.count_tokens(current_chunk + sentence_with_dot) > available_tokens:
                            if current_chunk:
                                chunks.append(current_chunk.strip())
                                current_chunk = sentence_with_dot
                            else:
                                # –ï—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ, —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
                                words = sentence.split()
                                for word in words:
                                    word_with_space = word + " "
                                    if self.count_tokens(current_chunk + word_with_space) > available_tokens:
                                        if current_chunk:
                                            chunks.append(current_chunk.strip())
                                            current_chunk = word_with_space
                                        else:
                                            # –î–∞–∂–µ –æ–¥–Ω–æ —Å–ª–æ–≤–æ –Ω–µ –ø–æ–º–µ—â–∞–µ—Ç—Å—è - –æ–±—Ä–µ–∑–∞–µ–º
                                            current_chunk = word_with_space
                                    else:
                                        current_chunk += word_with_space
                        else:
                            current_chunk += sentence_with_dot
            else:
                current_chunk += paragraph + "\n\n"
        
        if current_chunk:
            chunks.append(current_chunk.strip())
            
        return chunks
    
    async def process_chunk_with_retry(self, session: aiohttp.ClientSession, chunk: str, prompt: str, chunk_index: int, max_retries: int = 3) -> dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ rate limit"""
        for attempt in range(max_retries):
            try:
                result = await self.process_chunk(session, chunk, prompt, chunk_index)
                if result["success"]:
                    return result
                    
                # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ 429 (rate limit), –∂–¥–µ–º –∏ –ø–æ–≤—Ç–æ—Ä—è–µ–º
                if "429" in str(result.get("error", "")):
                    if self.paid_tier:
                        wait_time = 30 * (attempt + 1)  # –ú–µ–Ω—å—à–µ –æ–∂–∏–¥–∞–Ω–∏—è –¥–ª—è –ø–ª–∞—Ç–Ω–æ–≥–æ
                    else:
                        wait_time = 60 * (attempt + 1)  # –ë–æ–ª—å—à–µ –¥–ª—è free tier
                    
                    print(f"‚è≥ Rate limit –¥–ª—è —á–∞–Ω–∫–∞ {chunk_index + 1}, –æ–∂–∏–¥–∞–Ω–∏–µ {wait_time}—Å (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                    await asyncio.sleep(wait_time)
                    continue
                else:
                    return result
                    
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1} –¥–ª—è —á–∞–Ω–∫–∞ {chunk_index + 1}: {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(10 * (attempt + 1))
                    
        return {
            "chunk_index": chunk_index,
            "success": False,
            "error": f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫"
        }
    
    async def process_chunk(self, session: aiohttp.ClientSession, chunk: str, prompt: str, chunk_index: int) -> dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞ —á–µ—Ä–µ–∑ Gemini API"""
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.model}:generateContent?key={self.api_key}"
        
        headers = {"Content-Type": "application/json"}
        
        data = {
            "contents": [{"parts": [{"text": f"{prompt}\n\n–¢–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:\n{chunk}"}]}],
            "generationConfig": {
                "temperature": 0.7,
                "topK": 40,
                "topP": 0.95,
                "maxOutputTokens": 8192 if self.paid_tier else 4096,
                "candidateCount": 1
            },
            "safetySettings": [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"}
            ]
        }
        
        try:
            timeout = aiohttp.ClientTimeout(total=300 if self.paid_tier else 180)
            async with session.post(url, headers=headers, json=data, timeout=timeout) as response:
                if response.status == 200:
                    result = await response.json()
                    
                    if "candidates" in result and len(result["candidates"]) > 0:
                        candidate = result["candidates"][0]
                        if "content" in candidate and "parts" in candidate["content"]:
                            content = candidate["content"]["parts"][0]["text"]
                            
                            input_tokens = self.count_tokens(chunk + prompt)
                            output_tokens = self.count_tokens(content)
                            total_tokens = input_tokens + output_tokens
                            
                            print(f"‚úÖ –ß–∞–Ω–∫ {chunk_index + 1}: {input_tokens:,} + {output_tokens:,} = {total_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤")
                            return {
                                "chunk_index": chunk_index,
                                "success": True,
                                "content": content,
                                "tokens_used": total_tokens,
                                "input_tokens": input_tokens,
                                "output_tokens": output_tokens
                            }
                        else:
                            return {"chunk_index": chunk_index, "success": False, "error": "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini"}
                    else:
                        return {"chunk_index": chunk_index, "success": False, "error": "–ù–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ"}
                else:
                    error_text = await response.text()
                    return {"chunk_index": chunk_index, "success": False, "error": f"HTTP {response.status}: {error_text}"}
                    
        except Exception as e:
            return {"chunk_index": chunk_index, "success": False, "error": str(e)}
    
    async def process_file(self, file_path: str, prompt: str, output_path: str, chunk_size: int = 1000000, delay: int = 0, concurrent: int = 1):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞"""
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
            return False
        
        total_tokens = self.count_tokens(content)
        file_size_mb = len(content) / 1024 / 1024
        
        print(f"üìè –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {len(content):,} —Å–∏–º–≤–æ–ª–æ–≤ ({file_size_mb:.1f}MB)")
        print(f"üî¢ –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens:,}")
        
        chunks = self.split_into_chunks(content, prompt, chunk_size)
        print(f"üì¶ –§–∞–π–ª —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤ (–º–∞–∫—Å. {chunk_size:,} —Ç–æ–∫–µ–Ω–æ–≤ –∫–∞–∂–¥—ã–π)")
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if concurrent > 1:
            estimated_time = (len(chunks) * 15) / concurrent + (len(chunks) * delay)
        else:
            estimated_time = len(chunks) * (15 + delay)
        
        estimated_minutes = estimated_time / 60
        print(f"‚è±Ô∏è –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {estimated_minutes:.1f} –º–∏–Ω—É—Ç")
        
        if concurrent > 1:
            print(f"üöÄ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: {concurrent} –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
        
        results = []
        semaphore = asyncio.Semaphore(concurrent)
        
        connector = aiohttp.TCPConnector(limit=concurrent * 2)
        timeout = aiohttp.ClientTimeout(total=600)
        
        async def process_with_semaphore(session, chunk, i):
            async with semaphore:
                print(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ {i + 1}/{len(chunks)} ({datetime.now().strftime('%H:%M:%S')})")
                result = await self.process_chunk_with_retry(session, chunk, prompt, i)
                
                if delay > 0:
                    print(f"‚è∏Ô∏è –ó–∞–¥–µ—Ä–∂–∫–∞ {delay}—Å...")
                    await asyncio.sleep(delay)
                
                return result
        
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            if concurrent == 1:
                # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                for i, chunk in enumerate(chunks):
                    result = await process_with_semaphore(session, chunk, i)
                    results.append(result)
            else:
                # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                tasks = [process_with_semaphore(session, chunk, i) for i, chunk in enumerate(chunks)]
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏—è
                for i, result in enumerate(results):
                    if isinstance(result, Exception):
                        results[i] = {
                            "chunk_index": i,
                            "success": False,
                            "error": str(result)
                        }
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        successful_results = [r for r in results if isinstance(r, dict) and r.get("success")]
        failed_results = [r for r in results if isinstance(r, dict) and not r.get("success")]
        
        if failed_results:
            print(f"\n‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å {len(failed_results)} —á–∞–Ω–∫–æ–≤:")
            for failed in failed_results[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 5 –æ—à–∏–±–æ–∫
                print(f"   –ß–∞–Ω–∫ {failed.get('chunk_index', '?') + 1}: {failed.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
            if len(failed_results) > 5:
                print(f"   ... –∏ –µ—â–µ {len(failed_results) - 5} –æ—à–∏–±–æ–∫")
        
        if successful_results:
            try:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∏–Ω–¥–µ–∫—Å—É —á–∞–Ω–∫–∞
                successful_results.sort(key=lambda x: x['chunk_index'])
                
                final_content = "\n\n".join([
                    f"=== –†–ï–ó–£–õ–¨–¢–ê–¢ –ß–ê–ù–ö–ê {r['chunk_index'] + 1} ===\n{r['content']}"
                    for r in successful_results
                ])
                
                Path(output_path).parent.mkdir(parents=True, exist_ok=True)
                
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(final_content)
                
                total_tokens = sum(r.get("tokens_used", 0) for r in successful_results)
                total_input_tokens = sum(r.get("input_tokens", 0) for r in successful_results)
                total_output_tokens = sum(r.get("output_tokens", 0) for r in successful_results)
                
                print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                print(f"   üìä –£—Å–ø–µ—à–Ω–æ: {len(successful_results)}/{len(chunks)} —á–∞–Ω–∫–æ–≤")
                print(f"   üî¢ –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens:,}")
                print(f"   üì• –í—Ö–æ–¥—è—â–∏–µ: {total_input_tokens:,}")
                print(f"   üì§ –ò—Å—Ö–æ–¥—è—â–∏–µ: {total_output_tokens:,}")
                print(f"   üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç: {output_path}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                result_size = len(final_content) / 1024
                print(f"   üìè –†–∞–∑–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {result_size:.1f}KB")
                
                return len(failed_results) == 0  # True –µ—Å–ª–∏ –≤—Å–µ —á–∞–Ω–∫–∏ —É—Å–ø–µ—à–Ω—ã
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e}")
                return False
        else:
            print("\n‚ùå –ù–∏ –æ–¥–∏–Ω —á–∞–Ω–∫ –Ω–µ –±—ã–ª —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
            return False

def main():
    parser = argparse.ArgumentParser(description="–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ Gemini API")
    parser.add_argument("--file", required=True, help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É")
    parser.add_argument("--prompt", required=True, help="–ü—Ä–æ–º–ø—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    parser.add_argument("--output", required=True, help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É")
    parser.add_argument("--model", default="gemini-2.0-flash", help="–ú–æ–¥–µ–ª—å Gemini")
    parser.add_argument("--chunk-size", type=int, default=1000000, help="–†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ —Ç–æ–∫–µ–Ω–∞—Ö")
    parser.add_argument("--delay", type=int, default=0, help="–ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö")
    parser.add_argument("--concurrent", type=int, default=1, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
    parser.add_argument("--paid-tier", action="store_true", help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏–º–∏—Ç—ã –ø–ª–∞—Ç–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è")
    parser.add_argument("--api-key", help="API –∫–ª—é—á Gemini")
    
    args = parser.parse_args()
    
    api_key = args.api_key or os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("‚ùå –ù–µ —É–∫–∞–∑–∞–Ω API –∫–ª—é—á Gemini")
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é GEMINI_API_KEY –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ --api-key")
        sys.exit(1)
    
    if not os.path.exists(args.file):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.file}")
        sys.exit(1)
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    if args.concurrent < 1 or args.concurrent > 10:
        print("‚ùå –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ç 1 –¥–æ 10")
        sys.exit(1)
    
    if args.chunk_size < 1000 or args.chunk_size > 5000000:
        print("‚ùå –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 1,000 –¥–æ 5,000,000 —Ç–æ–∫–µ–Ω–æ–≤")
        sys.exit(1)
    
    processor = GeminiFileProcessor(api_key, args.model, args.paid_tier)
    
    start_time = time.time()
    
    try:
        success = asyncio.run(processor.process_file(
            args.file, 
            args.prompt, 
            args.output,
            args.chunk_size,
            args.delay,
            args.concurrent
        ))
        
        end_time = time.time()
        duration = end_time - start_time
        duration_minutes = duration / 60
        
        print(f"\nüèÅ –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration_minutes:.1f} –º–∏–Ω—É—Ç")
        
        if success:
            print("üéâ –í—Å–µ —á–∞–Ω–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
            sys.exit(0)
        else:
            print("‚ö†Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")
            sys.exit(2)  # –ß–∞—Å—Ç–∏—á–Ω—ã–π —É—Å–ø–µ—Ö
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
